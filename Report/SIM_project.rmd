---
title: "SIM - Project"
author: "Ignacio Lloret"
date: "2023-10-09"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse);library(EnvStats);library(ggplot2); library(ggpubr); library(visdat)
library(FactoMineR);library(DataExplorer);library(mice); library(lmtest);library(gridExtra); library(chemometrics); library(car);library(regclass)


setwd("C:/MDS/SIM/Project")
# setwd("C:/Users/inigo/Documents/UPC/SIM/SIM-project")
knitr::opts_chunk$set(warnign=FALSE, message=FALSE)


```

## Data Reading

```{r, read_data}
df <- read.csv("C:/MDS/SIM/Project/data/train.csv")
# df <- read.csv("C:/Users/inigo/Documents/UPC/SIM/SIM-project/data/train.csv")
```

## Keep columns

```{r, keep_data, fig.height=10}
##################
numeric_columns <- c("LotFrontage", "LotArea", "YearBuilt", "YearRemodAdd", "MasVnrArea", "BsmtFinSF1", "BsmtFinSF2", "BsmtUnfSF", "TotalBsmtSF", "X1stFlrSF", "X2ndFlrSF", "LowQualFinSF", "GrLivArea", "BsmtFullBath", "BsmtHalfBath", "FullBath", "HalfBath", "BedroomAbvGr", "KitchenAbvGr", "TotRmsAbvGrd", "Fireplaces", "GarageYrBlt", "GarageCars", "GarageArea", "WoodDeckSF", "OpenPorchSF", "EnclosedPorch", "X3SsnPorch", "ScreenPorch", "PoolArea", "MiscVal", "MoSold", "YrSold", "OverallCond","OverallQual","SalePrice")

cat_keep <- c("FireplaceQu","KitchenQual","BsmtFinType1","BsmtExposure","BsmtQual","Foundation","Neighborhood","LotShape","MSSubClass","Exterior1st","Exterior2nd", "SaleCondition")

df1 <- df %>% select(all_of(numeric_columns), all_of(cat_keep))
```

# Exploratory Data Analysis

## Missing data

```{r, missing_data, fig.height=3}

plot_missing(df1, missing_only = TRUE, group = list("Low" = 0.05, "Medium"=0.25, "High"=0.5, "Very High" =1), geom_label_args = list("size" = 2))

```

## Categorical values

```{r, categorical_plot}

df1[cat_keep] <- lapply(df1[cat_keep], as.factor) ## Create Factors
df1[numeric_columns] <- lapply(df1[numeric_columns], as.numeric) 


p1 <- df1 %>% 
  select(all_of(cat_keep)) %>%
  pivot_longer(cols=everything()) %>%
  ggplot(data=.) +
  geom_bar(aes(x=value), col="black", fill="white") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~name, scales="free", ncol=4)
p1
```

## Numerical Data

```{r, num_graphs, fig.height=20}

p2 <- df1 %>% 
  select(all_of(numeric_columns)) %>%
  pivot_longer(cols=everything()) %>%
  ggplot(data=.) +
  geom_boxplot(aes(y=value), col="black", fill="white") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~name, scales="free", ncol=4)
p2
```

## Normality Test

```{r, normality_test}
library(stats)
# Calculate mean and standard deviation
mean <- mean(df1$SalePrice)
sd <- sd(df1$SalePrice)

# Create a variable of sequence from minimum to maximum with 0.01 increments
x <- seq(min(df1$SalePrice), max(df1$SalePrice), length = 100)

# Add a 'Density' column to the data
data <- df1 %>%
  mutate(Density = dnorm(SalePrice, mean = mean, sd = sd))

# Generating the histogram
ggplot(data, aes(x = SalePrice)) +
  geom_histogram(aes(y = ..density..), bins = 30, colour = 'black', fill = 'white') +
  geom_line(aes(y = Density), colour = 'red') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


shapiro.test(df1$SalePrice) ## It is not normal

```

## Test serial correlation

```{r, serial correlation}
acf(df1$SalePrice, main="Autocorrelation Sale Price") 
dwtest(SalePrice ~1, data=df1)

```

There is no autocorrelation in the data as we see in the plot and in the Durbin Watson test. As the p-value is greater than .05.

## Outliers transformation

```{r, eval=FALSE, outlier_detection,fig.height=2, fig.width=4}
## Looking at the data exploration part we can distinguish multiple columns which have outliers, we will plot a geom_histogram to see them better

num_outliers <- c("BsmtFinSF1", "BsmtFinSF2", "BsmtHalfBath", "BsmtUnfSF", "EnclosedPorch", "GarageArea", "GrLivArea","LotArea", "LotFrontage", "LowQualFinSF", "MasVnrArea","MiscVal","OpenPorchSF","PoolArea","ScreenPorch","TotalBsmtSF", "WoodDeckSF","X1stFlrSF","X3SsnPorch")

# Create a list to store the plots
plots <- list()

columna <- "MasVnrArea"
# Loop through each numeric column
for(i in 1:length(num_outliers)) {
  columna <- num_outliers[i]
  
  # Calculate the thresholds
  q1 <- quantile(df1[columna],0.25, na.rm = TRUE) 
  q3 <- quantile(df1[columna],0.75, na.rm = TRUE) 
  iqr <- q3 - q1
  mild_l <- q1 - iqr*1.5
  mild_h <- q3 + iqr*1.5
  high_l <- q1 - iqr*3
  high_h <- q3 + iqr*3
  
  # Create the plot
  p <- ggplot(df1, aes(x=!!sym(columna))) +
    geom_histogram(color="black", fill="white", bins=30) +
    geom_vline(aes(xintercept=mild_l), color="blue", linetype="dashed") +
    geom_vline(aes(xintercept=mild_h), color="blue", linetype="dashed") +
    geom_vline(aes(xintercept=high_l), color="red", linetype="dashed") +
    geom_vline(aes(xintercept=high_h), color="red", linetype="dashed") +
    labs(x = columna, y="Frequency", title = paste("Histogram of", columna))
  # Add the plot to the list
  print(p)
}


## Multivariate 


```

The transformations we will do to the variables are the following. For the numeric values that have mild and extreme boundaries in 0, as they have near zero variability we will convert them to categorical. For the ones that show extreme values we will created a logarithmic transformation and for those which have little extreme outliers we will keep them as they are but we will be careful to not influence the models with these observations. So for the first case we will transform BsmtFinSF2, EnclosedPorch, LowQualFinSF, MiscVal, PoolArea, ScreenPorch, MasVnrArea. For the second case we will create log variables for: LotArea, LotFrontage, TotalBsmtSF, we will sum 1 in order to avoid the log(0). And we will keep them as they are the rest of them. These transformations will be held in the steps of transformation and categorization.

In our analysis with the Moutlier function, we faced issues due to the poor distribution of some numeric variables, which caused computational errors. To resolve this, we excluded variables with fewer than 50 unique values. This step was necessary to ensure the effectiveness of the outlier detection process, as variables with limited unique values can hinder the accurate identification of outliers. Additionally, we identified and removed multivariate outliers (moutliers) from our training dataset. These outliers are observations that significantly deviate from the norm across several dimensions. Removing these moutliers is crucial for enhancing model accuracy, as they can skew results and lead to misleading interpretations.

## NA imputation

```{r Data Exploratory, fig}

## Impute missing data by creating extra modality

df1$FireplaceQu <- ifelse(df1$FireplaceQu %>% is.na, "NoFirePlace", df1$FireplaceQu)
df1$BsmtExposure <- ifelse(df1$BsmtExposure %>% is.na, "NoBasement", df1$BsmtExposure)
df1$BsmtFinType1 <- ifelse(df1$BsmtFinType1 %>% is.na, "NoBasement", df1$BsmtFinType1)
df1$BsmtQual <- ifelse(df1$BsmtQual %>% is.na, "NoBasement", df1$BsmtQual)

df1$garage <- ifelse(df1$GarageYrBlt %>% is.na, "NO", "YES")
## Impute with synthetic values
df2 <- mice(df1, method = "cart")

df3 <- complete(df2)

plot_missing(df3, missing_only = FALSE, group = list("Zero"=0,"Low" = 0.05, "Medium"=0.25, "High"=0.5, "Very High" =1), geom_label_args = list("size" = 1))

```

After imputing the data logically, creating the levels NoFirePlace and NoBasement, we perform advanced imputation for imputing numerical values, creating sinthetic values.

## Correlation Matrix

```{r Correlation, fig.height=8, fig.width=8}


df_num <- df3[order(numeric_columns, decreasing = TRUE)]

plot_correlation(df_num)
```

## Numerical transformation

```{r, log_transformation, fig.height=5, fig.width=10}
df3$log_LotArea <- log(df3$LotArea + 1)
df3$log_LotFrontage <- log(df3$LotFrontage + 1)
df3$log_TotalBsmtSF <- log(df3$TotalBsmtSF + 1)

df3$YearRemodAdd <- df3$YearRemodAdd - df3$YearBuilt

g1 <- ggplot(df3) + geom_histogram(aes(x=log_LotArea))
g2 <- ggplot(df3) + geom_histogram(aes(x=log_LotFrontage))
g3 <- ggplot(df3) + geom_histogram(aes(x=log_TotalBsmtSF))

grid.arrange(g1,g2,g3, ncol=3)

df3$bsmt <- ifelse(df3$log_TotalBsmtSF == 0, "NO","YES")

```

In order to minimize the effect of 0 values in the dataset we will create a dummy variable for No Basement. It will be very useful for modelling as we will use it to create interactions with the numerical features.

## Categorization transformation

```{r, cat_transformation, fig.height=5, fig.width=10}

df3$cat_BsmntFinSF2 <- ifelse(df3$BsmtFinSF2 > 0, "Yes","Zero")
df3$cat_EnclosedPorch <- ifelse(df3$EnclosedPorch > 0, "Yes","Zero")
df3$cat_LowQualFinSF <- ifelse(df3$LowQualFinSF > 0, "Yes","Zero")
df3$cat_MiscVal <- ifelse(df3$MiscVal > 0, "Yes","Zero")
df3$cat_PoolArea <- ifelse(df3$PoolArea > 0, "Yes","No")
df3$cat_ScreenPorch <- ifelse(df3$ScreenPorch > 0, "Yes","No")
df3$cat_X3SsnPorch <- ifelse(df3$X3SsnPorch > 0, "Yes","No")
df3$remod <- ifelse(df3$YearRemodAdd == 0, "No", "Yes")

```

## Interaction between numerical and categorical

```{r}

ggplot(data=df3) +
  geom_boxplot(aes(y=SalePrice, x = Neighborhood, fill=Neighborhood))

ggplot(df, aes(x=MSZoning, y=SalePrice, fill=MSZoning)) +
    geom_boxplot() +
    labs(title="SalePrice vs MSZoning") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(df, aes(x=SaleCondition, y=SalePrice, fill=SaleCondition)) +
    geom_boxplot() +
    labs(title="SalePrice vs SaleCondition") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(df, aes(x=KitchenQual, y=SalePrice, fill=KitchenQual)) +
    geom_boxplot() +
    labs(title="SalePrice vs KitchenQual") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

The first graph shows the variation in sale prices of properties across different Neighborhoods.. The neighorhood can significantly influence its sale price.This graph helps to understand if certain neighorhoods have higher or lower average prices.

The second graph shows the variation in sale prices of properties across different municipal zoning classifications (MSZoning), which may include residential, commercial, agricultural, etc. The zoning of a property can significantly influence its sale price due to factors such as proximity to amenities, population density, and municipal regulations. This graph helps to understand if certain zones have higher or lower average prices.

The second graph compares the sale price with the sale condition (SaleCondition), which includes categories like normal, foreclosure, and urgency sale. The condition of the sale can reflect specific circumstances that affect the price, like urgent sales that might result in lower prices or normal condition sales that might reflect the market value. This analysis helps to identify if certain sale conditions are associated with significant price variations.

In the last graph, it's shown how the sale price varies with the quality of the kitchen (KitchenQual), which can be excellent, good, average, etc. The quality of a kitchen is a significant factor in property valuation. A high-quality kitchen can increase a property's value, while a low-quality one can decrease

### Multivariate outliers

```{r}

numeric_columns <- c("log_LotFrontage", "log_LotArea", "MasVnrArea", "BsmtFinSF1", "BsmtUnfSF", "log_TotalBsmtSF", "X1stFlrSF", "X2ndFlrSF", "GrLivArea", "BsmtFullBath", "BsmtHalfBath", "FullBath", "HalfBath", "BedroomAbvGr", "KitchenAbvGr", "TotRmsAbvGrd", "Fireplaces", "GarageYrBlt", "GarageCars", "GarageArea", "WoodDeckSF", "OpenPorchSF", "MoSold", "YrSold", "OverallCond","OverallQual","SalePrice")

df_clean = df3[complete.cases(df3[, numeric_columns]), numeric_columns]

sum(is.na(df_clean)) # Verificar valores faltantes

data_numeric <- df3[, sapply(df_clean, is.numeric)] # Filtra solo las variables numéricas

# Establece un umbral para el número de valores únicos
threshold <- 50

# Filtra las variables que tienen más valores únicos que el umbral
filtered_numeric_vars <- sapply(data_numeric, function(x) length(unique(x)) > threshold)
final_numeric_data <- data_numeric[, filtered_numeric_vars]


names(final_numeric_data)

# res.out = Moutlier(final_numeric_data[, !(names(final_numeric_data) %in% c("YearRemodAdd", # "MasVnrArea", "BsmtFinSF2", "X2ndFlrSF", "WoodDeckSF", "EnclosedPorch", "ScreenPorch"))], quantile = # 0.9995, col="green")
# 
# 
# outlier_index <- which((res.out$md > res.out$cutoff)&(res.out$rd > res.out$cutoff))
# length(outlier_index)
# 
# # [1] 39
# 
# par(mfrow=c(1,1))
# plot( res.out$md, res.out$rd )
# abline(h=res.out$cutoff, col="red")
# abline(v=res.out$cutoff, col="red")
# 
# df3 <- df3[!outlier_index, ]

```

## Model

```{r}
## First we will add all the variables that are do not have correlation between each other. We have iterated to keep those that are not multicolinear with each other by adding and removing. But keeping always the ones that we preprocessed.

df_model <- df3 %>% select(
  c(
    "log_LotFrontage",
    "log_LotArea",
    "YearBuilt",
    "YearRemodAdd",
    "FullBath",
    "garage",
    "GarageArea",
    "bsmt",
    "log_TotalBsmtSF",
    "cat_PoolArea",
    "YrSold",
    "MoSold",
    "remod",
    "GarageCars",
    "GarageYrBlt",
    "BedroomAbvGr",
    "KitchenAbvGr",
    "TotRmsAbvGrd",
    "Neighborhood",
    "GrLivArea",
    "MSSubClass",
    "X1stFlrSF",
    "X2ndFlrSF",
    "OverallCond",
    "OverallQual",
    "FireplaceQu",
    "cat_MiscVal",
    "OpenPorchSF", 
    "cat_EnclosedPorch",
    "cat_LowQualFinSF",
    "cat_X3SsnPorch",
    "ScreenPorch",
    "Foundation",
    "Exterior1st",
    "Exterior2nd",
    "SaleCondition",
    "SalePrice"
    )
)


attach(df_model)
mod1_raw <- lm(SalePrice ~ log_LotFrontage + log_LotArea + X1stFlrSF + X2ndFlrSF + YearBuilt + YearRemodAdd + FullBath + GarageArea + GarageCars + GarageYrBlt:garage + BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + Neighborhood + MSSubClass + log_TotalBsmtSF + cat_PoolArea + YrSold:MoSold + OverallCond + OverallQual + FireplaceQu + cat_MiscVal + OpenPorchSF + ScreenPorch + Foundation +SaleCondition, data=df_model)
summary(mod1_raw)
vif(mod1_raw) %>% round(2) %>% t


```

## Pruned model

```{r}
## Deleting not significant variables 
df_model <- df3 %>% select(
  c(
    "log_LotFrontage",
    "log_LotArea",
    "YearBuilt",
    "YearRemodAdd",
    "FullBath",
    "garage",
    "GarageArea",
    "bsmt",
    "log_TotalBsmtSF",
    "cat_PoolArea",
    "YrSold",
    "MoSold",
    "remod",
    "GarageCars",
    "GarageYrBlt",
    "BedroomAbvGr",
    "KitchenAbvGr",
    "TotRmsAbvGrd",
    "Neighborhood",
    "GrLivArea",
    "MSSubClass",
    "X1stFlrSF",
    "X2ndFlrSF",
    "OverallCond",
    "OverallQual",
    "FireplaceQu",
    "cat_MiscVal",
    "OpenPorchSF", 
    "cat_EnclosedPorch",
    "cat_LowQualFinSF",
    "cat_X3SsnPorch",
    "ScreenPorch",
    "Foundation",
    "Exterior1st",
    "Exterior2nd",
    "SaleCondition",
    "SalePrice"
    )
)
attach(df_model)
mod1 <- lm(SalePrice ~ log_LotFrontage + log_LotArea + X1stFlrSF + X2ndFlrSF + YearBuilt + GarageCars + BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + Neighborhood + MSSubClass + log_TotalBsmtSF + SaleCondition + OverallCond + OverallQual + FireplaceQu + ScreenPorch, data=df_model)
summary(mod1)
vif(mod1) %>% round(2) %>% t


## Stepwise 

mod_step <- step(mod1_raw, trace = FALSE)
summary(mod_step)

## So in the end little difference from removing not significant variables we will keep mod1 as the final one. 
```

## Validation

```{r}

plot(mod1)

## We can see that the extreme values are not being predicted very well so we will apply a log transformation in order to improve the performance. 

influencePlot(mod1)

hist(df3$SalePrice)
hist(df3$LotArea)
hist(df3$X1stFlrSF)
df3[c(524, 1299),] %>% select("LotArea","X1stFlrSF","SalePrice") 

## These are outliers because even though the house is very big, the price is not. We will remove them in order to generalize better.
df_model1 <- df_model[-c(524, 1299),]

mod2 <- lm(log(SalePrice) ~ log_LotFrontage + log_LotArea + X1stFlrSF + X2ndFlrSF + YearBuilt + GarageCars + BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + Neighborhood + MSSubClass + log_TotalBsmtSF + OverallCond + OverallQual + FireplaceQu + ScreenPorch, data=df_model1)

plot(mod2)
influencePlot(mod2)

```

## Interpretation of the model

```{r}
smod <- summary(mod2)
smod
```




## Test Preprocessing

```{r}

# df_test <- read.csv("C:/Users/inigo/Documents/UPC/SIM/SIM-project/data/test.csv")
df_test <- read.csv("C:/MDS/SIM/Project/data/test.csv")

numeric_columns <- c("LotFrontage", "LotArea", "YearBuilt", "YearRemodAdd", "MasVnrArea", "BsmtFinSF1", "BsmtFinSF2", "BsmtUnfSF", "TotalBsmtSF", "X1stFlrSF", "X2ndFlrSF", "LowQualFinSF", "GrLivArea", "BsmtFullBath", "BsmtHalfBath", "FullBath", "HalfBath", "BedroomAbvGr", "KitchenAbvGr", "TotRmsAbvGrd", "Fireplaces", "GarageYrBlt", "GarageCars", "GarageArea", "WoodDeckSF", "OpenPorchSF", "EnclosedPorch", "X3SsnPorch", "ScreenPorch", "PoolArea", "MiscVal", "MoSold", "YrSold", "OverallCond","OverallQual")

cat_keep <- c("FireplaceQu","KitchenQual","BsmtFinType1","BsmtExposure","BsmtQual","Foundation","Neighborhood","LotShape","MSSubClass","Exterior1st","Exterior2nd", "SaleCondition")

df1_test <- df_test %>% select(all_of(numeric_columns), all_of(cat_keep))

df1_test[cat_keep] <- lapply(df1_test[cat_keep], as.factor) ## Create Factors
df1_test[numeric_columns] <- lapply(df1_test[numeric_columns], as.numeric) 

num_outliers <- c("BsmtFinSF1", "BsmtFinSF2", "BsmtHalfBath", "BsmtUnfSF", "EnclosedPorch", "GarageArea", "GrLivArea","LotArea", "LotFrontage", "LowQualFinSF", "MasVnrArea","MiscVal","OpenPorchSF","PoolArea","ScreenPorch","TotalBsmtSF", "WoodDeckSF","X1stFlrSF","X3SsnPorch")

columna <- "MasVnrArea"
# Loop through each numeric column
for(i in 1:length(num_outliers)) {
  columna <- num_outliers[i]
  
  # Calculate the thresholds
  q1 <- quantile(df1_test[columna],0.25, na.rm = TRUE) 
  q3 <- quantile(df1_test[columna],0.75, na.rm = TRUE) 
  iqr <- q3 - q1
  mild_l <- q1 - iqr*1.5
  mild_h <- q3 + iqr*1.5
  high_l <- q1 - iqr*3
  high_h <- q3 + iqr*3
}


## Impute missing data by creating extra modality

df1_test$FireplaceQu <- ifelse(df1_test$FireplaceQu %>% is.na, "NoFirePlace", df1_test$FireplaceQu)
df1_test$BsmtExposure <- ifelse(df1_test$BsmtExposure %>% is.na, "NoBasement", df1_test$BsmtExposure)
df1_test$BsmtFinType1 <- ifelse(df1_test$BsmtFinType1 %>% is.na, "NoBasement", df1_test$BsmtFinType1)
df1_test$BsmtQual <- ifelse(df1_test$BsmtQual %>% is.na, "NoBasement", df1_test$BsmtQual)

df1_test$garage <- ifelse(df1_test$GarageYrBlt %>% is.na, "NO", "YES")
## Impute with synthetic values

plot_missing(df1_test, missing_only = TRUE)
plot_missing(df1, missing_only = TRUE)

df2_test <- mice(df1_test, method = "cart", m = 1)

df3_test <- complete(df2_test)

df3_test$log_LotArea <- log(df3_test$LotArea + 1)
df3_test$log_LotFrontage <- log(df3_test$LotFrontage + 1)
df3_test$log_TotalBsmtSF <- log(df3_test$TotalBsmtSF + 1)

df3_test$YearRemodAdd <- df3_test$YearRemodAdd - df3_test$YearBuilt

df3_test$bsmt <- ifelse(df3_test$log_TotalBsmtSF == 0, "NO","YES")

df3_test$cat_BsmntFinSF2 <- ifelse(df3_test$BsmtFinSF2 > 0, "Yes","Zero")
df3_test$cat_EnclosedPorch <- ifelse(df3_test$EnclosedPorch > 0, "Yes","Zero")
df3_test$cat_LowQualFinSF <- ifelse(df3_test$LowQualFinSF > 0, "Yes","Zero")
df3_test$cat_MiscVal <- ifelse(df3_test$MiscVal > 0, "Yes","Zero")
df3_test$cat_PoolArea <- ifelse(df3_test$PoolArea > 0, "Yes","No")
df3_test$cat_ScreenPorch <- ifelse(df3_test$ScreenPorch > 0, "Yes","No")
df3_test$cat_X3SsnPorch <- ifelse(df3_test$X3SsnPorch > 0, "Yes","No")
df3_test$remod <- ifelse(df3_test$YearRemodAdd == 0, "No", "Yes")

```

# Predictions of the test data
```{r}

df_model_test <- df3_test %>% select(
  c(
    "log_LotFrontage",
    "log_LotArea",
    "YearBuilt",
    "YearRemodAdd",
    "FullBath",
    "garage",
    "GarageArea",
    "bsmt",
    "log_TotalBsmtSF",
    "cat_PoolArea",
    "YrSold",
    "MoSold",
    "remod",
    "GarageCars",
    "GarageYrBlt",
    "BedroomAbvGr",
    "KitchenAbvGr",
    "TotRmsAbvGrd",
    "Neighborhood",
    "GrLivArea",
    "MSSubClass",
    "X1stFlrSF",
    "X2ndFlrSF",
    "OverallCond",
    "OverallQual",
    "FireplaceQu",
    "cat_MiscVal",
    "OpenPorchSF", 
    "cat_EnclosedPorch",
    "cat_LowQualFinSF",
    "cat_X3SsnPorch",
    "ScreenPorch",
    "Foundation",
    "Exterior1st",
    "Exterior2nd",
    "SaleCondition"
    )
)
attach(df_model_test)

df_model_test$MSSubClass %>% table

df_model_test <- df_model_test[!df_model_test$MSSubClass %in% c("150"), ]

predictions <- predict(mod2, newdata = df_model_test, type = "response")

final_predictions <- exp(predictions)


## Assessing forecasting capabilities
smp <- sample(x=nrow(df_model1),nrow(df_model1)*0.75, replace=FALSE)

train <- df_model1[smp,]
test <- df_model1[-smp,]


mod2 <- lm(log(SalePrice) ~ log_LotFrontage + log_LotArea + X1stFlrSF + X2ndFlrSF + YearBuilt + GarageCars + BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + Neighborhood + MSSubClass + log_TotalBsmtSF + OverallCond + OverallQual + FireplaceQu + ScreenPorch, data=train)

predictions <- predict(mod2, test)
predictions <- exp(predictions)

deviation <- (test$SalePrice - predictions)/test$SalePrice
deviation_abs <- (abs(test$SalePrice - predictions)/test$SalePrice)
mean(deviation)
## The median deviation is 8.8% 

g1 <- ggplot() + geom_jitter(mapping = aes(x=test$SalePrice, y=deviation, colour=deviation))
g2 <- ggplot() + geom_histogram(mapping = aes(x=deviation), fill="white", colour="black")
g3 <- ggplot() + geom_boxplot(mapping = aes(y=deviation), fill="cyan", colour="black")



# Create a data frame for the overlay
overlay_data <- data.frame(
  value = c(predictions, test$SalePrice),
  group = rep(c("Predictions", "Actual"), 
              each = c(length(predictions), length(test$SalePrice))
              )
)

# Create the histogram with ggplot2
g4 <- ggplot(overlay_data, aes(x = value, fill = group)) +
  geom_histogram(position = "identity", alpha = 0.5, bins = 30) +
  labs(title = "Histogram Overlay of Predictions and Actual SalePrice",
       x = "Sale Price",
       y = "Frequency") +
  scale_fill_manual(values = c("blue", "red")) 
## The distributions look very similar


grid.arrange(g1,g2,g3,g4)
```


